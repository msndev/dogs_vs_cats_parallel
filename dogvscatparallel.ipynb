{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV-em50X7o7F"
      },
      "source": [
        "# Parallel Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxP2adl57yd5"
      },
      "source": [
        "# Creating image paths for dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvF1ern8713t"
      },
      "source": [
        "datadir='/cotent/PetImages'\n",
        "p_training_data=[]\n",
        "\n",
        "Dog_categories=['Dog']\n",
        "for category in Dog_categories:\n",
        "  path=os.path.join(datadir,category) #path to cat or dog categories\n",
        "  imagePaths1=[os.path.join(path,img) for img in os.listdir(path)]\n",
        "\n",
        "Cat_categories=['Cat']\n",
        "for category in Cat_categories:\n",
        "  path=os.path.join(datadir,category) #path to cat or dog categories\n",
        "  imagePaths2=[os.path.join(path,img) for img in os.listdir(path)]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfggd1Jy9FIN"
      },
      "source": [
        "# Creating Dog dataset parallely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRmjz7q19IsZ"
      },
      "source": [
        "classifier=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvFPTxJb9QBQ"
      },
      "source": [
        "from multiprocessing import Pool\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "p_dog_training_data=[]\n",
        "start=time.time()\n",
        "\n",
        "def import_training_set(args):\n",
        "  c=0\n",
        "  global classifier\n",
        "  classifier+=1\n",
        "  index,imagePath,new_image_size=args\n",
        "  #Reads the image\n",
        "  image=cv2.imread(imagePath,cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "try:\n",
        "  input_vector=cv2.resize(image,new_image_size)\n",
        "  p_dog_training_data.append([input_vector,0])\n",
        "  return p_dog_training_data\n",
        "\n",
        "except Exception as e:\n",
        "  c+=1\n",
        "\n",
        "new_image_size=120,120\n",
        "number_of_parallel_processes=2\n",
        "\n",
        "ans1=Pool(number_of_parallel_processes).map(import_training_set,[(i,img,new_image_size) for i,img in enumerate(imagePaths1)])\n",
        "\n",
        "end=time.time()\n",
        "\n",
        "p_dog_dataset_creating_time=end-start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umfcnya8_g-A"
      },
      "source": [
        "print(p_dog_dataset_creating_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSCJuSFq_qSU"
      },
      "source": [
        "# Creating Cat dataset parallely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_dNud2l_uW4"
      },
      "source": [
        "from multiprocessing import Pool\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "p_cat_training_data=[]\n",
        "start=time.time()\n",
        "\n",
        "def import_training_set(args):\n",
        "  c=0\n",
        "  global classifier\n",
        "  classifier+=1\n",
        "  index,imagePath,new_image_size=args\n",
        "  #Reads the image\n",
        "  image=cv2.imread(imagePath,cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "try:\n",
        "  input_vector=cv2.resize(image,new_image_size)\n",
        "  p_cat_training_data.append([input_vector,1])\n",
        "  return p_cat_training_data\n",
        "\n",
        "except Exception as e:\n",
        "  c+=1\n",
        "\n",
        "new_image_size=120,120\n",
        "number_of_parallel_processes=2\n",
        "\n",
        "ans2=Pool(number_of_parallel_processes).map(import_training_set,[(i,img,new_image_size) for i,img in enumerate(imagePaths2)])\n",
        "\n",
        "end=time.time()\n",
        "\n",
        "p_cat_dataset_creating_time=end-start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS4HeCEsCv6S"
      },
      "source": [
        "print(p_cat_dataset_creating_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4p92RHGEyxt"
      },
      "source": [
        "Total time for creating dataset parallely"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49BM_qSWC0VD"
      },
      "source": [
        "p_total_dataset_creating_time=p_dog_dataset_creating_time+p_cat_dataset_creating_time\n",
        "print(p_total_dataset_creating_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doMqPa0XC-lW"
      },
      "source": [
        "# Training the dataset (model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS84dFUtDB8K"
      },
      "source": [
        "import tenserflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D\n",
        "\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "X1 = pickle.load(open(\"X1.pickle\",\"rb\"))\n",
        "y1 = pickle.load(open(\"y1.pickle\",\"rb\"))\n",
        "\n",
        "X1 = X1/255.0\n",
        "\n",
        "start=time.time()\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(64,(3,3),input_shape=X1.shape[1:]))\n",
        "\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64,(3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X,y,batch_size=20,epochs=10,validation_split=0.1)\n",
        "\n",
        "end=time.time()\n",
        "p_training_time = end-start\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5NLWwHNpKVU"
      },
      "source": [
        "Total time for training the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89m-aKZPGggp"
      },
      "source": [
        "print(p_training_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNSLaPP9Gzq6"
      },
      "source": [
        "# Total Parallel Execution Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtyqzYmvGkTt"
      },
      "source": [
        "total_parallel_execution_time=p_total_dataset_creating_time+p_training_time\n",
        "print(total_parallel_execution_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7om8I_eaFZwH"
      },
      "source": [
        "# Making a prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnPPAyU2FdbD"
      },
      "source": [
        "import cv2\n",
        "import tenserflow as tf\n",
        "\n",
        "categories=['Dog','Cat']\n",
        "\n",
        "def prepare(filepath):\n",
        "  image_size=120\n",
        "  a=cv2.imread(filepath)\n",
        "  a1=cv2.resize(a,(img_size,img_size))\n",
        "  return reshape(-1,img_size,img_size,1)\n",
        "\n",
        "prediction=model.predict([prepare('/cotent/dog1.png')])\n",
        "print(categories[int(prediction[0][0])])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}